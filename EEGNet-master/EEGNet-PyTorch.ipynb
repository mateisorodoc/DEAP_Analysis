{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T04:10:43.608046Z",
     "start_time": "2025-10-16T04:10:43.603396Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Written by, \n",
    "Sriram Ravindran, sriram@ucsd.edu\n",
    "\n",
    "Original paper - https://arxiv.org/abs/1611.08024\n",
    "\n",
    "Please reach out to me if you spot an error.\n",
    "\"\"\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nWritten by, \\nSriram Ravindran, sriram@ucsd.edu\\n\\nOriginal paper - https://arxiv.org/abs/1611.08024\\n\\nPlease reach out to me if you spot an error.\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:10:43.649813Z",
     "start_time": "2025-10-16T04:10:43.644609Z"
    }
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, precision_score, recall_score, accuracy_score\n",
    ")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Compiled with CUDA:\", torch.version.cuda)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "PyTorch version: 2.9.0\n",
      "CUDA available: False\n",
      "Compiled with CUDA: None\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here's the description from the paper</p>\n",
    "<img src=\"EEGNet.png\" style=\"width: 700px; float:left;\">"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:10:44.816604Z",
     "start_time": "2025-10-16T04:10:43.692562Z"
    }
   },
   "source": [
    "\n",
    "# ---------------------------\n",
    "# Squeeze-and-Excitation Block\n",
    "# ---------------------------\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n",
    "\n",
    "# ---------------------------\n",
    "# EEGNet with SE Attention\n",
    "# ---------------------------\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, T=120, C=32, dropout=0.25):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.T = T\n",
    "        self.C = C\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Layer 1: temporal conv across channels\n",
    "        self.conv1 = nn.Conv2d(1, 16, (1, C))  # kernel spans all 32 channels\n",
    "        self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        # Layer 2: spatial conv (depthwise) with more filters\n",
    "        self.padding1 = nn.ZeroPad2d((8, 8, 0, 1))\n",
    "        self.conv2 = nn.Conv2d(1, 16, (1, 16))\n",
    "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "        self.pooling2 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # SE block after Layer 2\n",
    "        self.se2 = SEBlock(16)\n",
    "\n",
    "        # Layer 3\n",
    "        self.padding2 = nn.ZeroPad2d((2, 1, 4, 3))\n",
    "        self.conv3 = nn.Conv2d(16, 16, (8, 4))\n",
    "        self.batchnorm3 = nn.BatchNorm2d(16)\n",
    "        self.pooling3 = nn.MaxPool2d((2, 4))\n",
    "\n",
    "        # Dynamically infer flatten size\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, T, C)\n",
    "            out = self._forward_features(dummy)\n",
    "            flatten_dim = out.shape[1]\n",
    "        print(f\"[EEGNet] Flattened feature dimension: {flatten_dim}\")\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc1 = nn.Linear(flatten_dim, 2)\n",
    "\n",
    "    def _forward_features(self, x):\n",
    "        # Layer 1\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Layer 2\n",
    "        x = self.padding1(x)\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.pooling2(x)\n",
    "\n",
    "        # Apply SE attention\n",
    "        x = self.se2(x)\n",
    "\n",
    "        # Layer 3\n",
    "        x = self.padding2(x)\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.batchnorm3(x)\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.pooling3(x)\n",
    "\n",
    "        # Flatten\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_features(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Usage Example\n",
    "# ---------------------------\n",
    "net = EEGNet(T=120, C=32, dropout=0.25).to(device)\n",
    "x_dummy = torch.rand(1, 1, 120, 32).to(device)\n",
    "output = net(x_dummy)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print(\"Output:\", output)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EEGNet] Flattened feature dimension: 448\n",
      "Output: tensor([[-0.0402,  0.0106]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate function returns values of different criteria like accuracy, precision etc.\n",
    "In case you face memory overflow issues, use batch size to control how many samples get evaluated at one time. Use a batch_size that is a factor of length of samples. This ensures that you won't miss any samples."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:10:44.877658Z",
     "start_time": "2025-10-16T04:10:44.871354Z"
    }
   },
   "source": [
    "def evaluate(model, X, Y, params=[\"acc\"], batch_size=100, device=None):\n",
    "    \"\"\"\n",
    "    Evaluate a trained multi-label EEGNet model on given data.\n",
    "\n",
    "    Args:\n",
    "        model: torch.nn.Module\n",
    "        X: numpy array, shape [samples, 1, timepoints, channels]\n",
    "        Y: numpy array, shape [samples, n_labels] (e.g., valence+arousal)\n",
    "        params: list of metrics to compute ['acc', 'auc', 'precision', 'recall', 'fmeasure']\n",
    "        batch_size: batch size for evaluation\n",
    "        device: torch.device (default: cuda if available)\n",
    "\n",
    "    Returns:\n",
    "        results: list of computed metrics (average across labels)\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    preds = []\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch_x = X[i:i + batch_size]\n",
    "        inputs = torch.tensor(batch_x, dtype=torch.float32).to(device)\n",
    "\n",
    "        with torch.no_grad():  # disable gradient computation\n",
    "            output = model(inputs)        # raw logits\n",
    "            output = torch.sigmoid(output)  # convert logits â†’ probabilities\n",
    "\n",
    "        preds.append(output.cpu().numpy())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    predicted = np.vstack(preds)  # shape: [samples, n_labels]\n",
    "\n",
    "    results = []\n",
    "    for param in params:\n",
    "        if param == \"acc\":\n",
    "            results.append(np.mean(np.round(predicted) == Y))  # average accuracy over labels\n",
    "        elif param == \"auc\":\n",
    "            results.append(roc_auc_score(Y, predicted, average='macro'))\n",
    "        elif param == \"recall\":\n",
    "            results.append(recall_score(Y, np.round(predicted), average='macro'))\n",
    "        elif param == \"precision\":\n",
    "            results.append(precision_score(Y, np.round(predicted), average='macro'))\n",
    "        elif param == \"fmeasure\":\n",
    "            precision = precision_score(Y, np.round(predicted), average='macro')\n",
    "            recall = recall_score(Y, np.round(predicted), average='macro')\n",
    "            results.append(2 * precision * recall / (precision + recall + 1e-8))  # avoid div0\n",
    "\n",
    "    model.train()  # switch back to training mode\n",
    "    return results\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:11:09.244052Z",
     "start_time": "2025-10-16T04:10:44.887205Z"
    }
   },
   "source": [
    "\n",
    "# Path to your DEAP folder\n",
    "# data_dir = r\"G:\\DEvAP\\data_preprocessed_python\"\n",
    "data_dir = \"/Users/mateisorodoc/Facultate/Licenta/DEAP_Data/data_preprocessed_python\"\n",
    "# Initialize lists\n",
    "all_data = []\n",
    "all_labels = []\n",
    "\n",
    "# Loop through subjects s01â€“s32\n",
    "for i in range(1, 33):\n",
    "    filename = f\"s{i:02d}.dat\"\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    print(f\"Loading {filename}...\")\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        subject_data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "    data = subject_data[\"data\"]      # shape: (40, 40, 8064)\n",
    "    labels = subject_data[\"labels\"]  # shape: (40, 4)\n",
    "\n",
    "    all_data.append(data)\n",
    "    all_labels.append(labels)\n",
    "\n",
    "# Stack into single numpy arrays\n",
    "data_all = np.vstack(all_data)       # shape: (1280, 40, 8064)\n",
    "labels_all = np.vstack(all_labels)   # shape: (1280, 4)\n",
    "\n",
    "print(\"All subjects loaded!\")\n",
    "print(\"Data shape:\", data_all.shape)\n",
    "print(\"Labels shape:\", labels_all.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading s01.dat...\n",
      "Loading s02.dat...\n",
      "Loading s03.dat...\n",
      "Loading s04.dat...\n",
      "Loading s05.dat...\n",
      "Loading s06.dat...\n",
      "Loading s07.dat...\n",
      "Loading s08.dat...\n",
      "Loading s09.dat...\n",
      "Loading s10.dat...\n",
      "Loading s11.dat...\n",
      "Loading s12.dat...\n",
      "Loading s13.dat...\n",
      "Loading s14.dat...\n",
      "Loading s15.dat...\n",
      "Loading s16.dat...\n",
      "Loading s17.dat...\n",
      "Loading s18.dat...\n",
      "Loading s19.dat...\n",
      "Loading s20.dat...\n",
      "Loading s21.dat...\n",
      "Loading s22.dat...\n",
      "Loading s23.dat...\n",
      "Loading s24.dat...\n",
      "Loading s25.dat...\n",
      "Loading s26.dat...\n",
      "Loading s27.dat...\n",
      "Loading s28.dat...\n",
      "Loading s29.dat...\n",
      "Loading s30.dat...\n",
      "Loading s31.dat...\n",
      "Loading s32.dat...\n",
      "All subjects loaded!\n",
      "Data shape: (1280, 40, 8064)\n",
      "Labels shape: (1280, 4)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:11:46.169737Z",
     "start_time": "2025-10-16T04:11:10.249846Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "n_trials, n_channels, n_samples = data_all.shape\n",
    "data_all = data_all[:, :32, :]  # keep first 32 channels\n",
    "segment_len = 120\n",
    "step = segment_len // 2  # 50% overlap\n",
    "n_segments = (n_samples - segment_len) // step + 1  # total segments per trial\n",
    "\n",
    "X_list = []\n",
    "Y_list = []\n",
    "\n",
    "print(f\"Segmenting {n_trials} trials into {n_segments} overlapping segments each...\")\n",
    "\n",
    "for trial in range(n_trials):\n",
    "    trial_data = data_all[trial]\n",
    "    trial_label = labels_all[trial]\n",
    "\n",
    "    for seg in range(n_segments):\n",
    "        start = seg * step\n",
    "        end = start + segment_len\n",
    "        segment = trial_data[:, start:end].T  # shape: (120, 32)\n",
    "\n",
    "        X_list.append(segment[np.newaxis, :, :])\n",
    "\n",
    "        valence = int(trial_label[0] > 5.0)\n",
    "        arousal = int(trial_label[1] > 5.0)\n",
    "        Y_list.append([valence, arousal])\n",
    "\n",
    "X = np.array(X_list, dtype=np.float32)\n",
    "Y = np.array(Y_list, dtype=np.float32)\n",
    "\n",
    "print(\"Done segmenting with 50% overlap!\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"Y shape:\", Y.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting 1280 trials into 133 overlapping segments each...\n",
      "Done segmenting with 50% overlap!\n",
      "X shape: (170240, 1, 120, 32)\n",
      "Y shape: (170240, 2)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-10-16T04:12:39.280211Z",
     "start_time": "2025-10-16T04:11:47.888536Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 70% training, 15% validation, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"X_val:\", X_val.shape, \"y_val:\", y_val.shape)\n",
    "print(\"X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (119168, 1, 120, 32) y_train: (119168, 2)\n",
      "X_val: (25536, 1, 120, 32) y_val: (25536, 2)\n",
      "X_test: (25536, 1, 120, 32) y_test: (25536, 2)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T04:27:27.466181Z",
     "start_time": "2025-10-16T04:12:44.394527Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import GradScaler, autocast\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "\n",
    "# ------------------------------\n",
    "# Hyperparameters\n",
    "# ------------------------------\n",
    "batch_size = 16\n",
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "max_grad_norm = 1.0  # optional gradient clipping\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net = net.to(device)\n",
    "optimizer = Adam(net.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)  # reduce LR every 30 epochs\n",
    "scaler = GradScaler()  # AMP scaler\n",
    "\n",
    "params = [\"acc\", \"auc\", \"fmeasure\"]\n",
    "\n",
    "# ------------------------------\n",
    "# Training loop\n",
    "# ------------------------------\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Shuffle training indices\n",
    "    indices = np.arange(len(X_train))\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_idx = indices[i:i + batch_size]\n",
    "        batch_x = torch.tensor(X_train[batch_idx], dtype=torch.float32).to(device)\n",
    "        batch_y = torch.tensor(y_train[batch_idx], dtype=torch.float32).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # AMP forward + backward\n",
    "        with autocast(device_type='cuda'):\n",
    "            outputs = net(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # Optional gradient clipping\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), max_grad_norm)\n",
    "\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # update learning rate\n",
    "    avg_loss = running_loss / (len(X_train) / batch_size)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # ------------------------------\n",
    "    # Evaluation\n",
    "    # ------------------------------\n",
    "    net.eval()\n",
    "    train_metrics = evaluate(net, X_train, y_train, params, device=device)\n",
    "    val_metrics = evaluate(net, X_val, y_val, params, device=device)\n",
    "    test_metrics = evaluate(net, X_test, y_test, params, device=device)\n",
    "\n",
    "    print(f\"Train     - {train_metrics}\")\n",
    "    print(f\"Validation- {val_metrics}\")\n",
    "    print(f\"Test      - {test_metrics}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/_r3vcp4n7sb2cl04h4q7xylc0000gn/T/ipykernel_29741/3386316923.py:21: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  scaler = GradScaler()  # AMP scaler\n",
      "/Users/mateisorodoc/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 - Training Loss: 0.6801\n",
      "Train     - [np.float64(0.582891380236305), 0.6129535129660459, 0.676479266138665]\n",
      "Validation- [np.float64(0.5823151629072681), 0.609983471299175, 0.6772653698214322]\n",
      "Test      - [np.float64(0.5843319235588973), 0.6156360677644579, 0.6763691323163753]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mateisorodoc/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 45\u001B[39m\n\u001B[32m     43\u001B[39m \u001B[38;5;66;03m# AMP forward + backward\u001B[39;00m\n\u001B[32m     44\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m autocast(device_type=\u001B[33m'\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m'\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m45\u001B[39m     outputs = \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_x\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     46\u001B[39m     loss = criterion(outputs, batch_y)\n\u001B[32m     48\u001B[39m scaler.scale(loss).backward()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 89\u001B[39m, in \u001B[36mEEGNet.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     88\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_forward_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     90\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.fc1(x)\n\u001B[32m     91\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 69\u001B[39m, in \u001B[36mEEGNet._forward_features\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# Layer 2\u001B[39;00m\n\u001B[32m     68\u001B[39m x = \u001B[38;5;28mself\u001B[39m.padding1(x)\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m x = F.elu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     70\u001B[39m x = \u001B[38;5;28mself\u001B[39m.batchnorm2(x)\n\u001B[32m     71\u001B[39m x = F.dropout(x, \u001B[38;5;28mself\u001B[39m.dropout, training=\u001B[38;5;28mself\u001B[39m.training)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1774\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1775\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1781\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1782\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1783\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1784\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1785\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1786\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1788\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1789\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:548\u001B[39m, in \u001B[36mConv2d.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    547\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m548\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Facultate/Licenta/DEAP_Analysis/EEGNet-master/venv/lib/python3.11/site-packages/torch/nn/modules/conv.py:543\u001B[39m, in \u001B[36mConv2d._conv_forward\u001B[39m\u001B[34m(self, input, weight, bias)\u001B[39m\n\u001B[32m    531\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.padding_mode != \u001B[33m\"\u001B[39m\u001B[33mzeros\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    532\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m F.conv2d(\n\u001B[32m    533\u001B[39m         F.pad(\n\u001B[32m    534\u001B[39m             \u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m._reversed_padding_repeated_twice, mode=\u001B[38;5;28mself\u001B[39m.padding_mode\n\u001B[32m   (...)\u001B[39m\u001B[32m    541\u001B[39m         \u001B[38;5;28mself\u001B[39m.groups,\n\u001B[32m    542\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m543\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    544\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\n\u001B[32m    545\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-16T04:27:27.531874Z",
     "start_time": "2025-10-06T18:59:00.598565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    outputs = net(inputs)  # shape: (402, 2)\n",
    "    probs = torch.sigmoid(outputs)  # convert logits â†’ probabilities [0,1]\n",
    "    preds = (probs > 0.5).int()     # threshold at 0.5 â†’ class 0 or 1\n",
    "\n",
    "# Move back to CPU for viewing\n",
    "pred_classes = preds.cpu().numpy()\n",
    "true_classes = y_test.astype(int)\n",
    "\n",
    "# Print some examples\n",
    "for i in range(10):\n",
    "    print(f\"Sample {i+1}: Predicted [Valence, Arousal] = {pred_classes[i]}, True = {true_classes[i]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: Predicted [Valence, Arousal] = [1 0], True = [0 1]\n",
      "Sample 2: Predicted [Valence, Arousal] = [1 1], True = [0 1]\n",
      "Sample 3: Predicted [Valence, Arousal] = [1 0], True = [1 1]\n",
      "Sample 4: Predicted [Valence, Arousal] = [1 1], True = [1 1]\n",
      "Sample 5: Predicted [Valence, Arousal] = [1 0], True = [1 1]\n",
      "Sample 6: Predicted [Valence, Arousal] = [0 1], True = [1 0]\n",
      "Sample 7: Predicted [Valence, Arousal] = [0 0], True = [1 1]\n",
      "Sample 8: Predicted [Valence, Arousal] = [1 1], True = [1 0]\n",
      "Sample 9: Predicted [Valence, Arousal] = [0 1], True = [1 1]\n",
      "Sample 10: Predicted [Valence, Arousal] = [1 1], True = [1 1]\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "ExecuteTime": {
     "end_time": "2025-10-16T04:27:27.567402Z",
     "start_time": "2025-10-06T18:59:01.167007Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
